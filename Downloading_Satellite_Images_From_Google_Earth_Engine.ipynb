{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Downloading_Satellite_Images_From_Google_Earth_Engine.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1eF7ipGrRrgy_zF5k7QtqbVA81M52XiV5",
      "authorship_tag": "ABX9TyN1d0E2SGKAdjsxo1/Br+qy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Max-FM/SPRINT-Colombia/blob/main/Downloading_Satellite_Images_From_Google_Earth_Engine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruk4Ycv3XHvS"
      },
      "source": [
        "#Downloading Satellite Images From Google Earth Engine "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkPRsp6S3WlQ"
      },
      "source": [
        "## Install geemap\n",
        "\n",
        "[geemap](https://geemap.readthedocs.io/en/latest/readme.html) is a useful package that adds additional functionality to the Google Earth Engine Python API."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "454blhwhof-f"
      },
      "source": [
        "%%capture\n",
        "\n",
        "!pip install geemap"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68_R807C3qLZ"
      },
      "source": [
        "##Import required packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9FdeMqVZCYU"
      },
      "source": [
        "import ee\n",
        "import folium\n",
        "import geemap.eefolium as emap"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tubT3goC3ua3"
      },
      "source": [
        "##Authenticate Google Earth Engine\n",
        "\n",
        "To access the Google Earth Engine API you require an account. To request access, go to [https://signup.earthengine.google.com](https://signup.earthengine.google.com/). You may have to wait up to a day or so to be granted access and it's possible you will not recieve any email communication. To manually check whether you have access, try to log into [https://code.earthengine.google.com](https://code.earthengine.google.com/), or attempt to run the next cell and follow the instructions provided in the output cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-uLIrdLZRoc",
        "outputId": "03e49485-946f-4bf2-e528-01e9bf91a537",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "# Trigger the authentication flow.\n",
        "ee.Authenticate()\n",
        "\n",
        "# Initialize the library.\n",
        "ee.Initialize()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "To authorize access needed by Earth Engine, open the following URL in a web browser and follow the instructions. If the web browser does not start automatically, please manually browse the URL below.\n",
            "\n",
            "    https://accounts.google.com/o/oauth2/auth?client_id=517222506229-vsmmajv00ul0bs7p89v5m89qs8eb9359.apps.googleusercontent.com&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fearthengine+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdevstorage.full_control&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&response_type=code&code_challenge=RpZE6GPBfnkfMSLkguuIT0mCQp3ghh6z_bSrcx0VhKk&code_challenge_method=S256\n",
            "\n",
            "The authorization workflow will generate a code, which you should paste in the box below. \n",
            "Enter verification code: 4/5gGx00lalfEgUcASMVdWmladCqXB4tq7cRFRgR-r6TNrNOjwwdsbPrc\n",
            "\n",
            "Successfully saved authorization token.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGrgSnJuXmk6"
      },
      "source": [
        "## Define Request Function\n",
        "\n",
        "Defines a series of Google Earth Image Collections that we wish to download images from. Image collections are filtered to a input geographical region, date range and maxiumum allowed cloud coverage."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDmWaq6BXybF"
      },
      "source": [
        "def obtain_data(region, start_date, end_date, months_either_side=0, max_cloud_cover=80):\n",
        "    start_date = ee.Date(start_date)\n",
        "    start_date = start_date.advance(-months_either_side, 'month')\n",
        "\n",
        "    end_date = ee.Date(end_date)\n",
        "    end_date = end_date.advance(months_either_side, 'month')\n",
        "    \n",
        "    # Filter input collections by desired date range, region and cloud coverage.\n",
        "    criteria  = ee.Filter.And(ee.Filter.geometry(region), \n",
        "                              ee.Filter.date(start_date, end_date))\n",
        "    \n",
        "    Sentinel_2_SR = ee.ImageCollection('COPERNICUS/S2_SR') \\\n",
        "                      .filter(criteria) \\\n",
        "                      .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', max_cloud_cover)) \\\n",
        "                      .select(['B4', 'B3', 'B2', 'B8'])\n",
        "\n",
        "    Sentinel_1_SAR_GRD_C_BAND = ee.ImageCollection(\"COPERNICUS/S1_GRD\") \\\n",
        "                                  .filter(criteria)\n",
        "\n",
        "    Landsat_8_T1_SR = ee.ImageCollection(\"LANDSAT/LC08/C01/T1_SR\") \\\n",
        "                        .filter(criteria) \\\n",
        "                        .filter(ee.Filter.lt('CLOUD_COVER', max_cloud_cover)) \\\n",
        "                        .select(['B4', 'B3', 'B2', 'B5'])\n",
        "\n",
        "    Landsat_7_T1_SR = ee.ImageCollection(\"LANDSAT/LE07/C01/T1_SR\") \\\n",
        "                        .filter(criteria) \\\n",
        "                        .filter(ee.Filter.lt('CLOUD_COVER', max_cloud_cover)) \\\n",
        "                        .select(['B3', 'B2', 'B1', 'B4'])\n",
        "\n",
        "    Landsat_5_T1_SR = ee.ImageCollection(\"LANDSAT/LT05/C01/T1_SR\") \\\n",
        "                        .filter(criteria) \\\n",
        "                        .filter(ee.Filter.lt('CLOUD_COVER', max_cloud_cover)) \\\n",
        "                        .select(['B3', 'B2', 'B1', 'B4'])\n",
        "\n",
        "    MODIS_16D_NDVI = ee.ImageCollection(\"MODIS/006/MOD13Q1\") \\\n",
        "                       .filter(criteria) \\\n",
        "                       .select('NDVI')\n",
        "\n",
        "    image_collections = {'Sentinel_2_SR': Sentinel_2_SR,\n",
        "                         'Sentinel_1_SAR_GRD_C_BAND': Sentinel_1_SAR_GRD_C_BAND,\n",
        "                         'Landsat_8_T1_SR': Landsat_8_T1_SR,\n",
        "                         'Landsat_7_T1_SR': Landsat_7_T1_SR,\n",
        "                         'Landsat_5_T1_SR': Landsat_5_T1_SR,\n",
        "                         'MODIS_16D_NDVI': MODIS_16D_NDVI}\n",
        "\n",
        "    return image_collections"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmL4FWUXWFOD"
      },
      "source": [
        "## Importing Dates from Spreadsheet and Extracting All Events\n",
        "\n",
        "Imports spreadsheet containing disaster information for the test districts. Specifically the date ranges of the disaster to feed to the request function defined above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_J0uK62WEzN",
        "outputId": "53717cee-5e1d-4616-b8bd-e6060ba2da0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "extreme_weather_table = pd.read_excel('/content/drive/Shared drives/Colombia SPRINT/Test Districts/Colombia extreme weather in test districts.xlsx')\n",
        "\n",
        "extreme_weather_table[['Disaster', 'Start Year', 'Month', 'Day', 'End Year', 'End Month', 'End Day']]\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Disaster</th>\n",
              "      <th>Start Year</th>\n",
              "      <th>Month</th>\n",
              "      <th>Day</th>\n",
              "      <th>End Year</th>\n",
              "      <th>End Month</th>\n",
              "      <th>End Day</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Drought</td>\n",
              "      <td>1998</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1998</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Earthquake</td>\n",
              "      <td>1999</td>\n",
              "      <td>1.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1999</td>\n",
              "      <td>1.0</td>\n",
              "      <td>25.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Flood</td>\n",
              "      <td>1999</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1999</td>\n",
              "      <td>5.0</td>\n",
              "      <td>19.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Flood</td>\n",
              "      <td>1999</td>\n",
              "      <td>10.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>1999</td>\n",
              "      <td>12.0</td>\n",
              "      <td>31.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Flood</td>\n",
              "      <td>2000</td>\n",
              "      <td>5.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>2000</td>\n",
              "      <td>5.0</td>\n",
              "      <td>24.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Wildfire</td>\n",
              "      <td>2001</td>\n",
              "      <td>8.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2001</td>\n",
              "      <td>8.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Drought</td>\n",
              "      <td>2002</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2003</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Flood</td>\n",
              "      <td>2002</td>\n",
              "      <td>4.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>2002</td>\n",
              "      <td>4.0</td>\n",
              "      <td>29.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Flood</td>\n",
              "      <td>2003</td>\n",
              "      <td>8.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2003</td>\n",
              "      <td>12.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Flood</td>\n",
              "      <td>2004</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2004</td>\n",
              "      <td>6.0</td>\n",
              "      <td>28.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Drought</td>\n",
              "      <td>2004</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2005</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Flood</td>\n",
              "      <td>2005</td>\n",
              "      <td>4.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>2005</td>\n",
              "      <td>5.0</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Flood</td>\n",
              "      <td>2005</td>\n",
              "      <td>9.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>2005</td>\n",
              "      <td>11.0</td>\n",
              "      <td>17.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Flood</td>\n",
              "      <td>2006</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2006</td>\n",
              "      <td>4.0</td>\n",
              "      <td>27.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Drought</td>\n",
              "      <td>2006</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2007</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Flood</td>\n",
              "      <td>2007</td>\n",
              "      <td>10.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>2007</td>\n",
              "      <td>10.0</td>\n",
              "      <td>26.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Flood</td>\n",
              "      <td>2008</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2008</td>\n",
              "      <td>5.0</td>\n",
              "      <td>19.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Flood</td>\n",
              "      <td>2008</td>\n",
              "      <td>11.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>2009</td>\n",
              "      <td>1.0</td>\n",
              "      <td>12.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Wildfire</td>\n",
              "      <td>2010</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2010</td>\n",
              "      <td>4.0</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Flood</td>\n",
              "      <td>2010</td>\n",
              "      <td>10.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>2011</td>\n",
              "      <td>1.0</td>\n",
              "      <td>12.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Flood</td>\n",
              "      <td>2011</td>\n",
              "      <td>2.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>2011</td>\n",
              "      <td>6.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Flood</td>\n",
              "      <td>2011</td>\n",
              "      <td>9.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2011</td>\n",
              "      <td>12.0</td>\n",
              "      <td>31.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Flood</td>\n",
              "      <td>2012</td>\n",
              "      <td>3.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>2012</td>\n",
              "      <td>5.0</td>\n",
              "      <td>14.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Flood</td>\n",
              "      <td>2013</td>\n",
              "      <td>9.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>2013</td>\n",
              "      <td>12.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Earthquake</td>\n",
              "      <td>2013</td>\n",
              "      <td>2.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>2013</td>\n",
              "      <td>2.0</td>\n",
              "      <td>9.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Drought</td>\n",
              "      <td>2015</td>\n",
              "      <td>8.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2016</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Storm</td>\n",
              "      <td>2016</td>\n",
              "      <td>9.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>2016</td>\n",
              "      <td>9.0</td>\n",
              "      <td>23.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>Flood</td>\n",
              "      <td>2017</td>\n",
              "      <td>3.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>2017</td>\n",
              "      <td>5.0</td>\n",
              "      <td>16.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Flood</td>\n",
              "      <td>2017</td>\n",
              "      <td>12.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2018</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Drought</td>\n",
              "      <td>2018</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2020</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>Flood</td>\n",
              "      <td>2019</td>\n",
              "      <td>2.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>2019</td>\n",
              "      <td>2.0</td>\n",
              "      <td>26.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>Flood</td>\n",
              "      <td>2020</td>\n",
              "      <td>6.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>2020</td>\n",
              "      <td>6.0</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Disaster  Start Year  Month   Day  End Year  End Month  End Day\n",
              "0      Drought        1998    1.0   NaN      1998        NaN      NaN\n",
              "1   Earthquake        1999    1.0  25.0      1999        1.0     25.0\n",
              "2        Flood        1999    1.0  10.0      1999        5.0     19.0\n",
              "3        Flood        1999   10.0  28.0      1999       12.0     31.0\n",
              "4        Flood        2000    5.0  18.0      2000        5.0     24.0\n",
              "5     Wildfire        2001    8.0   NaN      2001        8.0      NaN\n",
              "6      Drought        2002    NaN   NaN      2003        NaN      NaN\n",
              "7        Flood        2002    4.0  24.0      2002        4.0     29.0\n",
              "8        Flood        2003    8.0   NaN      2003       12.0      NaN\n",
              "9        Flood        2004    1.0   NaN      2004        6.0     28.0\n",
              "10     Drought        2004    NaN   NaN      2005        NaN      NaN\n",
              "11       Flood        2005    4.0  12.0      2005        5.0      7.0\n",
              "12       Flood        2005    9.0  15.0      2005       11.0     17.0\n",
              "13       Flood        2006    1.0   1.0      2006        4.0     27.0\n",
              "14     Drought        2006    NaN   NaN      2007        NaN      NaN\n",
              "15       Flood        2007   10.0  20.0      2007       10.0     26.0\n",
              "16       Flood        2008    1.0   1.0      2008        5.0     19.0\n",
              "17       Flood        2008   11.0  16.0      2009        1.0     12.0\n",
              "18    Wildfire        2010    1.0   NaN      2010        4.0      6.0\n",
              "19       Flood        2010   10.0  30.0      2011        1.0     12.0\n",
              "20       Flood        2011    2.0  10.0      2011        6.0      5.0\n",
              "21       Flood        2011    9.0   1.0      2011       12.0     31.0\n",
              "22       Flood        2012    3.0  15.0      2012        5.0     14.0\n",
              "23       Flood        2013    9.0  15.0      2013       12.0      1.0\n",
              "24  Earthquake        2013    2.0   9.0      2013        2.0      9.0\n",
              "25     Drought        2015    8.0   NaN      2016        2.0      NaN\n",
              "26       Storm        2016    9.0  20.0      2016        9.0     23.0\n",
              "27       Flood        2017    3.0  17.0      2017        5.0     16.0\n",
              "28       Flood        2017   12.0   1.0      2018        1.0      7.0\n",
              "29     Drought        2018    NaN   NaN      2020        NaN      NaN\n",
              "30       Flood        2019    2.0  20.0      2019        2.0     26.0\n",
              "31       Flood        2020    6.0  10.0      2020        6.0     10.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwiWAKACdURZ",
        "outputId": "2fdb5539-8ba4-4427-9e9d-684b1961c4e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Filling in empty values for dates.\n",
        "extreme_weather_table['Day'].fillna(1, inplace=True)\n",
        "extreme_weather_table['Month'].fillna(1, inplace=True)\n",
        "extreme_weather_table['End Day'].fillna(1, inplace=True)\n",
        "extreme_weather_table['End Month'].fillna(1, inplace=True)\n",
        "\n",
        "# Dealing with duplicate start/end dates.\n",
        "extreme_weather_table.loc[0, 'End Year'] = 1999 # Assuming this drought lasts a year.\n",
        "extreme_weather_table.loc[31, 'End Month'] = 7 # Assuming this flood event lasts a month.\n",
        "\n",
        "# Converting date columns into a single datetime column.\n",
        "extreme_weather_table['Start_Datetime'] = pd.to_datetime(extreme_weather_table['Start Year'].astype(str) + '-' +\n",
        "                                          extreme_weather_table['Month'].astype(int).astype(str) + '-' +\n",
        "                                          extreme_weather_table['Day'].astype(int).astype(str))\n",
        "\n",
        "extreme_weather_table['End_Datetime'] = pd.to_datetime(extreme_weather_table['End Year'].astype(str) + '-' +\n",
        "                                        extreme_weather_table['End Month'].astype(int).astype(str) + '-' +\n",
        "                                        extreme_weather_table['End Day'].astype(int).astype(str))\n",
        "\n",
        "extreme_weather_table[['Disaster', 'Start_Datetime', 'End_Datetime']]\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Disaster</th>\n",
              "      <th>Start_Datetime</th>\n",
              "      <th>End_Datetime</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Drought</td>\n",
              "      <td>1998-01-01</td>\n",
              "      <td>1999-01-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Earthquake</td>\n",
              "      <td>1999-01-25</td>\n",
              "      <td>1999-01-25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Flood</td>\n",
              "      <td>1999-01-10</td>\n",
              "      <td>1999-05-19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Flood</td>\n",
              "      <td>1999-10-28</td>\n",
              "      <td>1999-12-31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Flood</td>\n",
              "      <td>2000-05-18</td>\n",
              "      <td>2000-05-24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Wildfire</td>\n",
              "      <td>2001-08-01</td>\n",
              "      <td>2001-08-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Drought</td>\n",
              "      <td>2002-01-01</td>\n",
              "      <td>2003-01-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Flood</td>\n",
              "      <td>2002-04-24</td>\n",
              "      <td>2002-04-29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Flood</td>\n",
              "      <td>2003-08-01</td>\n",
              "      <td>2003-12-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Flood</td>\n",
              "      <td>2004-01-01</td>\n",
              "      <td>2004-06-28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Drought</td>\n",
              "      <td>2004-01-01</td>\n",
              "      <td>2005-01-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Flood</td>\n",
              "      <td>2005-04-12</td>\n",
              "      <td>2005-05-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Flood</td>\n",
              "      <td>2005-09-15</td>\n",
              "      <td>2005-11-17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Flood</td>\n",
              "      <td>2006-01-01</td>\n",
              "      <td>2006-04-27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Drought</td>\n",
              "      <td>2006-01-01</td>\n",
              "      <td>2007-01-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Flood</td>\n",
              "      <td>2007-10-20</td>\n",
              "      <td>2007-10-26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Flood</td>\n",
              "      <td>2008-01-01</td>\n",
              "      <td>2008-05-19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Flood</td>\n",
              "      <td>2008-11-16</td>\n",
              "      <td>2009-01-12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Wildfire</td>\n",
              "      <td>2010-01-01</td>\n",
              "      <td>2010-04-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Flood</td>\n",
              "      <td>2010-10-30</td>\n",
              "      <td>2011-01-12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Flood</td>\n",
              "      <td>2011-02-10</td>\n",
              "      <td>2011-06-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Flood</td>\n",
              "      <td>2011-09-01</td>\n",
              "      <td>2011-12-31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Flood</td>\n",
              "      <td>2012-03-15</td>\n",
              "      <td>2012-05-14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Flood</td>\n",
              "      <td>2013-09-15</td>\n",
              "      <td>2013-12-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Earthquake</td>\n",
              "      <td>2013-02-09</td>\n",
              "      <td>2013-02-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Drought</td>\n",
              "      <td>2015-08-01</td>\n",
              "      <td>2016-02-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Storm</td>\n",
              "      <td>2016-09-20</td>\n",
              "      <td>2016-09-23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>Flood</td>\n",
              "      <td>2017-03-17</td>\n",
              "      <td>2017-05-16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Flood</td>\n",
              "      <td>2017-12-01</td>\n",
              "      <td>2018-01-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Drought</td>\n",
              "      <td>2018-01-01</td>\n",
              "      <td>2020-01-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>Flood</td>\n",
              "      <td>2019-02-20</td>\n",
              "      <td>2019-02-26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>Flood</td>\n",
              "      <td>2020-06-10</td>\n",
              "      <td>2020-07-10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Disaster Start_Datetime End_Datetime\n",
              "0      Drought     1998-01-01   1999-01-01\n",
              "1   Earthquake     1999-01-25   1999-01-25\n",
              "2        Flood     1999-01-10   1999-05-19\n",
              "3        Flood     1999-10-28   1999-12-31\n",
              "4        Flood     2000-05-18   2000-05-24\n",
              "5     Wildfire     2001-08-01   2001-08-01\n",
              "6      Drought     2002-01-01   2003-01-01\n",
              "7        Flood     2002-04-24   2002-04-29\n",
              "8        Flood     2003-08-01   2003-12-01\n",
              "9        Flood     2004-01-01   2004-06-28\n",
              "10     Drought     2004-01-01   2005-01-01\n",
              "11       Flood     2005-04-12   2005-05-07\n",
              "12       Flood     2005-09-15   2005-11-17\n",
              "13       Flood     2006-01-01   2006-04-27\n",
              "14     Drought     2006-01-01   2007-01-01\n",
              "15       Flood     2007-10-20   2007-10-26\n",
              "16       Flood     2008-01-01   2008-05-19\n",
              "17       Flood     2008-11-16   2009-01-12\n",
              "18    Wildfire     2010-01-01   2010-04-06\n",
              "19       Flood     2010-10-30   2011-01-12\n",
              "20       Flood     2011-02-10   2011-06-05\n",
              "21       Flood     2011-09-01   2011-12-31\n",
              "22       Flood     2012-03-15   2012-05-14\n",
              "23       Flood     2013-09-15   2013-12-01\n",
              "24  Earthquake     2013-02-09   2013-02-09\n",
              "25     Drought     2015-08-01   2016-02-01\n",
              "26       Storm     2016-09-20   2016-09-23\n",
              "27       Flood     2017-03-17   2017-05-16\n",
              "28       Flood     2017-12-01   2018-01-07\n",
              "29     Drought     2018-01-01   2020-01-01\n",
              "30       Flood     2019-02-20   2019-02-26\n",
              "31       Flood     2020-06-10   2020-07-10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heXTfEEOEmZ0"
      },
      "source": [
        "##Downloading Imaging for All Events"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VH5njU7A7-Gu"
      },
      "source": [
        "disaster = 'Flood' # Options are 'Flood', 'Drought', 'Wildfire', 'Earthquake' and 'Storm'."
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Db98zNMvD3B2",
        "outputId": "18535d7b-7cf5-4e42-9d5a-35c307e49361",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "# Points to the geometries uploaded to Google Earth Engine for each test district.\n",
        "test_districts = {'Dosquebradas': ee.FeatureCollection('users/maxfoxley-marrable/SPRINT/Dosquebradas'),\n",
        "                  'Corpo Versailles': ee.FeatureCollection('users/maxfoxley-marrable/SPRINT/Versailles')}\n",
        "\n",
        "# Defines the desired pixel scale for each image, have set to the native \n",
        "# resolution of each satellite.\n",
        "scale_dict = {'Sentinel_2_SR': 10,\n",
        "              'Sentinel_1_SAR_GRD_C_BAND': 10,\n",
        "              'Landsat_8_T1_SR': 30,\n",
        "              'Landsat_7_T1_SR': 30,\n",
        "              'Landsat_5_T1_SR': 30,\n",
        "              'MODIS_16D_NDVI': 250}\n",
        "\n",
        "# Defines the desired bands, specifically when making a timelapse GIF.\n",
        "bands_dict = {'Sentinel_2_SR': ['B4', 'B3', 'B2'], \n",
        "            #   'Sentinel_1_SAR_GRD_C_BAND': \n",
        "              'Landsat_8_T1_SR': ['B4', 'B3', 'B2'],\n",
        "              'Landsat_7_T1_SR': ['B3', 'B2', 'B1'],\n",
        "              'Landsat_5_T1_SR': ['B3', 'B2', 'B1'],\n",
        "              'MODIS_16D_NDVI': 'NDVI'} \n",
        "\n",
        "\n",
        "if disaster == 'Drought':\n",
        "    # Probably only want MODIS 16D Imagery for droughts.\n",
        "    desired_collections = ['MODIS_16D_NDVI'] \n",
        "else:\n",
        "    # e.g ['Sentinel_2_SR', 'Landsat_8_T1_SR', etc]. Selects all if empty/None.\n",
        "    desired_collections = None \n",
        "\n",
        "# Create a tuple of strings containing start and end dates to be iterated \n",
        "# through later on.\n",
        "start_date_list = list(extreme_weather_table[extreme_weather_table['Disaster'] == disaster]['Start_Datetime'].astype(str))\n",
        "end_date_list = list(extreme_weather_table[extreme_weather_table['Disaster'] == disaster]['End_Datetime'].astype(str))\n",
        "\n",
        "# Zips start and end dates into a list of tuples.\n",
        "date_ranges = list(zip(start_date_list, end_date_list))\n",
        "\n",
        "display(date_ranges)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[('1999-01-10', '1999-05-19'),\n",
              " ('1999-10-28', '1999-12-31'),\n",
              " ('2000-05-18', '2000-05-24'),\n",
              " ('2002-04-24', '2002-04-29'),\n",
              " ('2003-08-01', '2003-12-01'),\n",
              " ('2004-01-01', '2004-06-28'),\n",
              " ('2005-04-12', '2005-05-07'),\n",
              " ('2005-09-15', '2005-11-17'),\n",
              " ('2006-01-01', '2006-04-27'),\n",
              " ('2007-10-20', '2007-10-26'),\n",
              " ('2008-01-01', '2008-05-19'),\n",
              " ('2008-11-16', '2009-01-12'),\n",
              " ('2010-10-30', '2011-01-12'),\n",
              " ('2011-02-10', '2011-06-05'),\n",
              " ('2011-09-01', '2011-12-31'),\n",
              " ('2012-03-15', '2012-05-14'),\n",
              " ('2013-09-15', '2013-12-01'),\n",
              " ('2017-03-17', '2017-05-16'),\n",
              " ('2017-12-01', '2018-01-07'),\n",
              " ('2019-02-20', '2019-02-26'),\n",
              " ('2020-06-10', '2020-07-10')]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFbSaJW73lFM",
        "outputId": "6dd098b9-5851-4a3b-b7f5-a06e779fc3e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Iterating through each of the test districts.\n",
        "for district_name, district_geom in test_districts.items():\n",
        "    # Defines base directory to save images to.\n",
        "    drive_dir = f'/content/drive/Shared drives/Colombia SPRINT/Test Districts/{district_name}/Extreme Weather Event Imagery/{disaster}s/'\n",
        "    %cd '{drive_dir}'\n",
        "\n",
        "    # Iterating through the date ranges for the chosen disaster type.\n",
        "    for start_date, end_date in date_ranges:\n",
        "\n",
        "        # Obtains all image collections defined in the request function for \n",
        "        # the chosen test district and date range. Looking 2 months either side\n",
        "        # of the given date range and with maximum 80% cloud cover.\n",
        "        image_collections = obtain_data(district_geom, \n",
        "                                        start_date, \n",
        "                                        end_date,\n",
        "                                        months_either_side=2,\n",
        "                                        max_cloud_cover=80)\n",
        "        \n",
        "        # Filters out unwanted collections if defined above.\n",
        "        if desired_collections:\n",
        "            image_collections = {collection: image_collections[collection] \\\n",
        "                                 for collection in desired_collections}\n",
        "        \n",
        "        # Creates a subfolder in the base directory for the start date of the \n",
        "        # disaster.\n",
        "        out_dir = f'{start_date}'\n",
        "        print(out_dir)\n",
        "        !mkdir '{out_dir}'\n",
        "\n",
        "        # Iterating through each image collection.\n",
        "        for collection_name, collection in image_collections.items():\n",
        "            # Skips the image collection if it contains no images.\n",
        "            if collection.size().getInfo() == 0:\n",
        "                print('No images in collection, skipping.')\n",
        "                continue\n",
        "            # Creates additional subfolders for each image collection. \n",
        "            collection_dir = f'{out_dir}/{collection_name}'\n",
        "            print(collection_dir)\n",
        "            !mkdir '{collection_dir}'\n",
        "\n",
        "            # Exports each image in the filtered image collection to \n",
        "            # geoTIFF format.\n",
        "            emap.ee_export_image_collection(collection, \n",
        "                                            collection_dir,\n",
        "                                            crs='EPSG:4326',\n",
        "                                            scale=scale_dict[collection_name],\n",
        "                                            region=district_geom.geometry().bounds())\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/Shared drives/Colombia SPRINT/Test Districts/Dosquebradas/Extreme Weather Event Imagery/Floods\n",
            "1999-01-10\n",
            "mkdir: cannot create directory ‘1999-01-10’: File exists\n",
            "No images in collection, skipping.\n",
            "1999-10-28\n",
            "mkdir: cannot create directory ‘1999-10-28’: File exists\n",
            "No images in collection, skipping.\n",
            "2000-05-18\n",
            "mkdir: cannot create directory ‘2000-05-18’: File exists\n",
            "No images in collection, skipping.\n",
            "2002-04-24\n",
            "mkdir: cannot create directory ‘2002-04-24’: File exists\n",
            "No images in collection, skipping.\n",
            "2003-08-01\n",
            "mkdir: cannot create directory ‘2003-08-01’: File exists\n",
            "No images in collection, skipping.\n",
            "2004-01-01\n",
            "mkdir: cannot create directory ‘2004-01-01’: File exists\n",
            "No images in collection, skipping.\n",
            "2005-04-12\n",
            "mkdir: cannot create directory ‘2005-04-12’: File exists\n",
            "No images in collection, skipping.\n",
            "2005-09-15\n",
            "mkdir: cannot create directory ‘2005-09-15’: File exists\n",
            "No images in collection, skipping.\n",
            "2006-01-01\n",
            "mkdir: cannot create directory ‘2006-01-01’: File exists\n",
            "No images in collection, skipping.\n",
            "2007-10-20\n",
            "mkdir: cannot create directory ‘2007-10-20’: File exists\n",
            "No images in collection, skipping.\n",
            "2008-01-01\n",
            "mkdir: cannot create directory ‘2008-01-01’: File exists\n",
            "No images in collection, skipping.\n",
            "2008-11-16\n",
            "mkdir: cannot create directory ‘2008-11-16’: File exists\n",
            "No images in collection, skipping.\n",
            "2010-10-30\n",
            "mkdir: cannot create directory ‘2010-10-30’: File exists\n",
            "No images in collection, skipping.\n",
            "2011-02-10\n",
            "mkdir: cannot create directory ‘2011-02-10’: File exists\n",
            "No images in collection, skipping.\n",
            "2011-09-01\n",
            "mkdir: cannot create directory ‘2011-09-01’: File exists\n",
            "No images in collection, skipping.\n",
            "2012-03-15\n",
            "mkdir: cannot create directory ‘2012-03-15’: File exists\n",
            "No images in collection, skipping.\n",
            "2013-09-15\n",
            "mkdir: cannot create directory ‘2013-09-15’: File exists\n",
            "No images in collection, skipping.\n",
            "2017-03-17\n",
            "mkdir: cannot create directory ‘2017-03-17’: File exists\n",
            "2017-03-17/Sentinel_1_SAR_GRD_C_BAND\n",
            "mkdir: cannot create directory ‘2017-03-17/Sentinel_1_SAR_GRD_C_BAND’: File exists\n",
            "Total number of images: 35\n",
            "\n",
            "Exporting 1/35: S1A_IW_GRDH_1SDV_20170414T105047_20170414T105117_016139_01AA86_D04E.tif\n",
            "Generating URL ...\n",
            "Downloading data from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/19d5c27b800b08d53e908d655d1580e9-fdfd4949602e3b996e1e62818b6656a0:getPixels\n",
            "Please wait ...\n",
            "Data downloaded to /content/drive/Shared drives/Colombia SPRINT/Test Districts/Dosquebradas/Extreme Weather Event Imagery/Floods/2017-03-17/Sentinel_1_SAR_GRD_C_BAND/S1A_IW_GRDH_1SDV_20170414T105047_20170414T105117_016139_01AA86_D04E.tif\n",
            "\n",
            "\n",
            "Exporting 2/35: S1A_IW_GRDH_1SDV_20170426T105047_20170426T105117_016314_01AFE1_CEA3.tif\n",
            "Generating URL ...\n",
            "Downloading data from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/bf9b7545534791978dec5aef73649d12-864b4b853f4e4523c743fec7ec4d90d4:getPixels\n",
            "Please wait ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    376\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 2.7, use buffering of HTTP responses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m                 \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: getresponse() got an unexpected keyword argument 'buffering'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-ecf0219d093f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m                                             \u001b[0mcrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'EPSG:4326'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                                             \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscale_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcollection_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                                             region=district_geom.geometry().bounds())\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/geemap/eefolium.py\u001b[0m in \u001b[0;36mee_export_image_collection\u001b[0;34m(ee_object, out_dir, scale, crs, region, file_per_band)\u001b[0m\n\u001b[1;32m   1580\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Exporting {}/{}: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1581\u001b[0m             ee_export_image(image, filename=filename, scale=scale,\n\u001b[0;32m-> 1582\u001b[0;31m                             crs=crs, region=region, file_per_band=file_per_band)\n\u001b[0m\u001b[1;32m   1583\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/geemap/eefolium.py\u001b[0m in \u001b[0;36mee_export_image\u001b[0;34m(ee_object, filename, scale, crs, region, file_per_band)\u001b[0m\n\u001b[1;32m   1518\u001b[0m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mee_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetDownloadURL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Downloading data from {}\\nPlease wait ...'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1520\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    528\u001b[0m         }\n\u001b[1;32m    529\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    447\u001b[0m                     \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m                 )\n\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    598\u001b[0m                                                   \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m                                                   chunked=chunked)\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m             \u001b[0;31m# If we're going to release the connection in ``finally:``, then\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m                     \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m                     \u001b[0;31m# Remove the TypeError from the exception chain in Python 3;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1354\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1010\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1012\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Read on closed or unwrapped SSL socket.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSSL_ERROR_EOF\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    629\u001b[0m         \"\"\"\n\u001b[1;32m    630\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6Ucq4ju4j7J"
      },
      "source": [
        "##Create Timelapse GIFs of Each Image Collection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2QrET604iYY",
        "outputId": "1bda5dd9-095d-400d-afb6-563003fa8056",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 819
        }
      },
      "source": [
        "f# Iterating through each of the test districts.\n",
        "for district_name, district_geom in test_districts.items():\n",
        "    # Defines base directory to save images to.\n",
        "    drive_dir = f'/content/drive/Shared drives/Colombia SPRINT/Test Districts/{district_name}/Extreme Weather Event Imagery/{disaster}s/'\n",
        "    %cd '{drive_dir}'\n",
        "\n",
        "    # Iterating through the date ranges for the chosen disaster type.\n",
        "    for start_date, end_date in date_ranges:\n",
        "\n",
        "        # Obtains all image collections defined in the request function for \n",
        "        # the chosen test district and date range. Looking 2 months either side\n",
        "        # of the given date range and with maximum 80% cloud cover.\n",
        "        image_collections = obtain_data(district_geom, \n",
        "                                        start_date, \n",
        "                                        end_date,\n",
        "                                        months_either_side=2,\n",
        "                                        max_cloud_cover=80)\n",
        "        \n",
        "        # Filters out unwanted collections if defined above.\n",
        "        if desired_collections:\n",
        "            image_collections = {collection: image_collections[collection] \\\n",
        "                                 for collection in desired_collections}\n",
        "\n",
        "        out_dir = f'{start_date}'\n",
        "        print(out_dir)\n",
        "\n",
        "        # Iterating through each image collection.\n",
        "        for collection_name, collection in image_collections.items():\n",
        "            # Skips the image collection if it contains no images.\n",
        "            if collection.size().getInfo() == 0:\n",
        "                print('No images in collection, skipping.')\n",
        "                continue\n",
        "            \n",
        "            # Defines GIF parameters depending on the image collection. In this\n",
        "            # case, specifically for NDVI and RGB images.\n",
        "            if collection_name == 'MODIS_16D_NDVI':\n",
        "                gif_params = {'bands': bands_dict[collection_name],\n",
        "                              'dimensions': 1000,\n",
        "                              'crs': 'EPSG:4326',\n",
        "                              'framesPerSecond': 1,\n",
        "                              'min': 0,\n",
        "                              'max': 8000,\n",
        "                              'palette': ['FFFFFF', 'CE7E45', 'DF923D', 'F1B555', 'FCD163', '99B718', '74A901',\n",
        "                                          '66A000', '529400', '3E8601', '207401', '056201', '004C00', '023B01',\n",
        "                                          '012E01', '011D01', '011301'],\n",
        "                              'region': district_geom.geometry().bounds()}\n",
        "            \n",
        "            else:\n",
        "                gif_params = {'bands': bands_dict[collection_name],\n",
        "                              'dimensions': 1000,\n",
        "                              'crs': 'EPSG:4326',\n",
        "                              'framesPerSecond': 1,\n",
        "                              'min': 0, \n",
        "                              'max': 3000,\n",
        "                              'region': district_geom.geometry().bounds()}\n",
        "\n",
        "            gif_path = f'{out_dir}/{collection_name}_{start_date}.gif'\n",
        "\n",
        "            # Outputs image collection into a timelapse gif.\n",
        "            emap.download_ee_video(collection, \n",
        "                                   gif_params,\n",
        "                                   gif_path)\n",
        "            "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/Shared drives/Colombia SPRINT/Test Districts/Dosquebradas/Extreme Weather Event Imagery/Droughts\n",
            "1998-01-01\n",
            "No images in collection, skipping.\n",
            "2002-01-01\n",
            "Generating URL...\n",
            "Downloading GIF image from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/videoThumbnails/456792bcb1e00a5e37e968d05688a666-89bc7978dc3270fdf3c117f269b73dfe:getPixels\n",
            "Please wait ...\n",
            "The GIF image has been saved to: /content/drive/Shared drives/Colombia SPRINT/Test Districts/Dosquebradas/Extreme Weather Event Imagery/Droughts/2002-01-01/MODIS_16D_NDVI_2002-01-01.gif\n",
            "2004-01-01\n",
            "Generating URL...\n",
            "Downloading GIF image from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/videoThumbnails/74589b7fef96d442d246bc4323d5bd45-12eac273dbf062aa6d5d98a905361c3e:getPixels\n",
            "Please wait ...\n",
            "The GIF image has been saved to: /content/drive/Shared drives/Colombia SPRINT/Test Districts/Dosquebradas/Extreme Weather Event Imagery/Droughts/2004-01-01/MODIS_16D_NDVI_2004-01-01.gif\n",
            "2006-01-01\n",
            "Generating URL...\n",
            "Downloading GIF image from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/videoThumbnails/84ce9abe5334f05ce260d0ef6695001d-bee72db40d86b1ff3b38c48c21916560:getPixels\n",
            "Please wait ...\n",
            "The GIF image has been saved to: /content/drive/Shared drives/Colombia SPRINT/Test Districts/Dosquebradas/Extreme Weather Event Imagery/Droughts/2006-01-01/MODIS_16D_NDVI_2006-01-01.gif\n",
            "2015-08-01\n",
            "Generating URL...\n",
            "Downloading GIF image from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/videoThumbnails/0ba2e14846ef70a9b25c3a18aae173e0-81bf23078b8413b7a6c43079b5661a25:getPixels\n",
            "Please wait ...\n",
            "The GIF image has been saved to: /content/drive/Shared drives/Colombia SPRINT/Test Districts/Dosquebradas/Extreme Weather Event Imagery/Droughts/2015-08-01/MODIS_16D_NDVI_2015-08-01.gif\n",
            "2018-01-01\n",
            "Generating URL...\n",
            "Total request size (44874000 pixels) must be less than or equal to 26214400 pixels.\n",
            "/content/drive/Shared drives/Colombia SPRINT/Test Districts/Corpo Versailles/Extreme Weather Event Imagery/Droughts\n",
            "1998-01-01\n",
            "No images in collection, skipping.\n",
            "2002-01-01\n",
            "Generating URL...\n",
            "Total request size (27125000 pixels) must be less than or equal to 26214400 pixels.\n",
            "2004-01-01\n",
            "Generating URL...\n",
            "Total request size (27125000 pixels) must be less than or equal to 26214400 pixels.\n",
            "2006-01-01\n",
            "Generating URL...\n",
            "Total request size (27125000 pixels) must be less than or equal to 26214400 pixels.\n",
            "2015-08-01\n",
            "Generating URL...\n",
            "Downloading GIF image from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/videoThumbnails/5dd52bbe8287f9ad52726636389beb3e-901c75f0e74c9665a28fe033962d489e:getPixels\n",
            "Please wait ...\n",
            "The GIF image has been saved to: /content/drive/Shared drives/Colombia SPRINT/Test Districts/Corpo Versailles/Extreme Weather Event Imagery/Droughts/2015-08-01/MODIS_16D_NDVI_2015-08-01.gif\n",
            "2018-01-01\n",
            "Generating URL...\n",
            "Total request size (47250000 pixels) must be less than or equal to 26214400 pixels.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}